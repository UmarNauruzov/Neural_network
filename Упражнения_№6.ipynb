{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UmarNauruzov/Neural_network/blob/main/%D0%A3%D0%BF%D1%80%D0%B0%D0%B6%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F_%E2%84%966.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQp47ajD2Ga4"
      },
      "source": [
        "# Знакомство с word2vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_Pat15ls9N8"
      },
      "source": [
        "## Загрузка модели\n",
        "Скачаем модель <code>google-news-vectors</code>. Откроем ее с помощью библиотеки <code>gensim</code>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd-xNyAGy1tT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a44fe4e-2269-4c4f-b3dd-c050f48bab2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/usr/local/lib/python3.9/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM \n",
            "\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.5.1 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.\n",
            "gensim 4.3.1 requires scipy>=1.7.0, but you have scipy 1.5.4 which is incompatible.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.5.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -q -U gensim\n",
        "! gdown --id 0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
        "! pip install -q SciPy==1.5.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "metadata": {
        "id": "t9CnRiM9kL8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d27afa-5b9a-4049-ae67-26ee97399735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: GoogleNews-vectors-negative300.bin.gz: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4xfcycMynhZ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "w = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/GoogleNews-vectors-negative300.bin\", \n",
        "                                      binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6JtQjaORfzA"
      },
      "source": [
        "Структура называется <code>KeyedVectors</code> и по сути представляет собой отображение между ключами и векторами. Каждый вектор идентифицируется своим ключом поиска, чаще всего коротким строковым токеном, поэтому обычно это соответствие между\n",
        "\n",
        "<center><code>{str => 1D numpy array}</code></center><br/>\n",
        "\n",
        "\n",
        "\n",
        "Например, выведем первые 10 координат вектора, соответствующего слову <code>sunrise</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol9DuE6VRfzH",
        "outputId": "6eb39eb5-c204-419f-d789-5c5c662560ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность вектора:  (300,)\n",
            "Первые 10 координат вектора: \n",
            " [-0.22558594 -0.03540039 -0.21679688  0.03613281 -0.2265625  -0.09814453\n",
            "  0.109375   -0.34570312  0.18652344  0.01806641]\n"
          ]
        }
      ],
      "source": [
        "print(\"Размерность вектора: \", w[\"sunrise\"].shape)\n",
        "print(\"Первые 10 координат вектора: \\n\", w[\"sunrise\"][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mns8gpJFRfzd"
      },
      "source": [
        "Извлеките векторы слов <code>London</code>, <code>England</code>, <code>Moscow</code>. Посчитайте косинусное расстояние между словами <code>London</code> и <code>England</code> и между словами <code>Moscow</code> и <code>England</code>. Какая пара слов ближе? Подсказка: для вычисления косинусного расстояния использвется метод <code>distance()</code>. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t2XOM4es9rd",
        "outputId": "a551c16e-4527-44ce-cd51-2214af32e0c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9IrMkVi3Crm",
        "outputId": "ad26b9d4-695d-4ed8-c6ee-13cbfcd78479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Косинусное расстояние между словами London и England: 0.8389686495065689\n",
            "Косинусное расстояние между словами Moscow и England: 0.8389686495065689\n",
            "Слова Moscow и England ближе друг к другу\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "# получаем векторы слов\n",
        "london_vec = w['media']\n",
        "england_vec = w['bread']\n",
        "\n",
        "\n",
        "# считаем косинусное расстояние между словами\n",
        "london_england_distance = w.distance('media', 'bread')\n",
        "moscow_england_distance = w.distance('bread', 'media')\n",
        "\n",
        "# выводим результаты\n",
        "print(f\"Косинусное расстояние между словами London и England: {london_england_distance}\")\n",
        "print(f\"Косинусное расстояние между словами Moscow и England: {moscow_england_distance}\")\n",
        "\n",
        "if london_england_distance < moscow_england_distance:\n",
        "    print(\"Слова London и England ближе друг к другу\")\n",
        "else:\n",
        "    print(\"Слова Moscow и England ближе друг к другу\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLXEcSxt3DG4"
      },
      "source": [
        "## Задание 2. Аналогии.\n",
        "С помощью метода most_similar решите аналогию\n",
        "```London : England = Moscow : X```\n",
        "\n",
        "Правильный ответ представлен в блоке вывода.\n",
        "\n",
        "(Подсказка: нужно использовать аргументы positive и negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Pqub5c3DV8",
        "outputId": "51d1dee1-f4a8-4de3-c814-2d4ab79beac1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Russia', 0.6502718329429626),\n",
              " ('Ukraine', 0.5879061818122864),\n",
              " ('Belarus', 0.5666376352310181),\n",
              " ('Azerbaijan', 0.5418694615364075),\n",
              " ('Armenia', 0.5300518870353699),\n",
              " ('Poland', 0.5253247618675232),\n",
              " ('coach_Georgy_Yartsev', 0.5220180749893188),\n",
              " ('Russian', 0.5214669108390808),\n",
              " ('Croatia', 0.5166040658950806),\n",
              " ('Moldova', 0.5125792026519775)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w.most_similar(positive=['Moscow', 'England'], negative=['London'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzneqrn3Djq"
      },
      "source": [
        "\n",
        "С помощью метода <code>doesnt_match</code> найдите лишнее слово в ряду <code>breakfast cereal dinner lunch</code>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "493uH-D33DxJ",
        "outputId": "526caec5-c56a-4be9-fbca-96b2769e279f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лишнее слово: media\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "\n",
        "#model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "\n",
        "word_list = [\"media\", \"bread\", \"cucumber\", \"doctor\"]\n",
        "\n",
        "# находим лишнее слово\n",
        "odd_word = w.doesnt_match(word_list)\n",
        "\n",
        "print(\"Лишнее слово:\", odd_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT-Zl3YaRf0X"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm_SiyjU3D9G"
      },
      "source": [
        "\n",
        "Дано предложение: <code>the quick brown fox jumps over the lazy dog</code>. Вам нужно представить это предложение в виде вектора. Для этого найдите вектор каждого слова в модели, а затем усредните векторы покомпонентно.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FbM9gOT3Ofg",
        "outputId": "bca18a1f-264c-4ae7-b4a9-6c58a3ff6034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Первые 5 координат вектора-предложения: [ 0.09055582  0.05434163 -0.06713867  0.10968696 -0.01060655]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "\n",
        "# Разбить предложение на токены\n",
        "tokens = ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
        "\n",
        "# Получить векторы для каждого слова\n",
        "vectors = [w.get_vector(token) for token in tokens]\n",
        "\n",
        "# Усреднить векторы покомпонентно\n",
        "sentence_vector = np.mean(vectors, axis=0)\n",
        "\n",
        "# Вывести первые 5 координат вектора-предложения\n",
        "print(\"Первые 5 координат вектора-предложения:\", sentence_vector[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нахождение расстояния между предложениями "
      ],
      "metadata": {
        "id": "OPyT9xEKiXY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "import gensim.downloader as api\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import scipy.spatial.distance as ds\n",
        "\n",
        "# Разбить предложение на токены\n",
        "tokens1 = ['chain', 'is', 'only', 'as', 'strong', 'as', 'its', 'weakest', 'link']\n",
        "\n",
        "vectors1 = [w.get_vector(token1) for token1 in tokens1]\n",
        "\n",
        "# Усреднить векторы покомпонентно\n",
        "sentence_vector1 = np.mean(vectors1, axis=0)\n",
        "\n",
        "tokens2 = ['actions', 'speak', 'louder', 'than', 'words']\n",
        "\n",
        "vectors2 = [w.get_vector(token2) for token2 in tokens2]\n",
        "# Усреднить векторы покомпонентно\n",
        "sentence_vector2 = np.mean(vectors2, axis=0)\n",
        "\n",
        "similarity = ds.cosine(sentence_vector1, sentence_vector2)\n",
        "\n",
        "print(\"Косинусное расстояние между предложениями:\", similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGYG9qOx8uSx",
        "outputId": "74ed614d-d053-437e-9022-c8aff55d8e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Косинусное расстояние между предложениями: 0.7841248512268066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Еще один вариант, только ответ не правильный"
      ],
      "metadata": {
        "id": "QqIDjfCsGegF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Предложения\n",
        "sentence1 = 'chain is only as strong as its weakest link'\n",
        "sentence2 = 'Actions speak louder than words'\n",
        "\n",
        "# Получить векторы слов для каждого предложения\n",
        "vec_sentence1 = []\n",
        "for word in sentence1.split():\n",
        "    try:\n",
        "        vec = w[word]\n",
        "        vec_sentence1.append(vec)\n",
        "    except KeyError:\n",
        "        pass\n",
        "\n",
        "vec_sentence2 = []\n",
        "for word in sentence2.split():\n",
        "    try:\n",
        "        vec = w[word]\n",
        "        vec_sentence2.append(vec)\n",
        "    except KeyError:\n",
        "        pass\n",
        "\n",
        "# Усреднить векторы слов для каждого предложения\n",
        "vec_avg_sentence1 = np.mean(vec_sentence1, axis=0)\n",
        "vec_avg_sentence2 = np.mean(vec_sentence2, axis=0)\n",
        "\n",
        "# Рассчитать косинусное расстояние между векторами предложений\n",
        "similarity = cosine_similarity(vec_avg_sentence1.reshape(1, -1), vec_avg_sentence2.reshape(1, -1))[0][0]\n",
        "\n",
        "print(1-(similarity))\n"
      ],
      "metadata": {
        "id": "rrkGwHHNP0wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3hwN53r5un"
      },
      "source": [
        "# Сравнение двух моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-HvrEkHtFqQ"
      },
      "source": [
        "## Загрузка ещё одной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z13Io-4x3Ve2"
      },
      "source": [
        "\n",
        "Откроем модель google-news-vectors и модель, обученную на британском национальном корпусе http://vectors.nlpl.eu/repository/20/0.zip, с помощью gensim. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QPYDnlz3X2B",
        "outputId": "892fdde1-76c7-4cec-fff4-7fd180831cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-16 12:59:07--  http://vectors.nlpl.eu/repository/20/0.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 344050746 (328M) [application/zip]\n",
            "Saving to: ‘0.zip’\n",
            "\n",
            "0.zip               100%[===================>] 328.11M  23.2MB/s    in 15s     \n",
            "\n",
            "2023-03-16 12:59:23 (21.7 MB/s) - ‘0.zip’ saved [344050746/344050746]\n",
            "\n",
            "Archive:  0.zip\n",
            "  inflating: meta.json               \n",
            "  inflating: model.bin               \n",
            "  inflating: model.txt               \n",
            "  inflating: README                  \n",
            "163473 300\n",
            "say_VERB -0.008861 0.097097 0.100236 0.070044 -0.079279 0.000923 -0.012829 0.064301 -0.029405 -0.009858 -0.017753 0.063115 0.033623 0.019805 0.052704 -0.100458 0.089387 -0.040792 -0.088936 0.110212 -0.044749 0.077675 -0.017062 -0.063745 -0.009502 -0.079371 0.066952 -0.070209 0.063761 -0.038194 -0.046252 0.049983 -0.094985 -0.086341 0.024665 -0.112857 -0.038358 -0.007008 -0.010063 -0.000183 0.068841 0.024942 -0.042561 -0.044576 0.010776 0.006323 0.088285 -0.062522 0.028216 0.088291 0.033231 -0.033732 -0.002995 0.118994 0.000453 0.158588 -0.044475 -0.137629 0.066080 0.062824 -0.128369 -0.087959 0.028080 0.070063 0.046700 -0.083278 -0.118428 0.071118 0.100757 0.017944 0.026296 0.017282 -0.082127 -0.006148 0.002967 -0.032857 -0.076493 -0.072842 -0.055179 -0.081703 0.011437 -0.038698 -0.062540 -0.027899 0.087635 0.031870 0.029164 0.000524 -0.039895 -0.055559 0.024582 -0.030595 0.003942 -0.034500 0.003012 -0.023863 0.033831 0.061476 -0.090183 -0.039206 -0.026586 -0.042763 0.049835 -0.052496 -0.020044 0.073703 0.096775 0.033063 0.000313 -0.022581 -0.141154 0.032095 0.077733 -0.063739 -0.055647 -0.017604 0.044639 -0.062925 -0.001960 0.024665 -0.009416 -0.021381 0.082724 -0.031026 0.027255 0.066198 0.000845 0.008393 0.039434 0.054104 -0.060255 0.034266 0.079435 0.043624 -0.015871 -0.038030 -0.030374 -0.020542 0.007132 0.008708 0.087840 0.017351 -0.089493 0.030182 0.026961 -0.071212 -0.004854 0.007389 0.067203 -0.026351 -0.011460 -0.058723 0.013153 -0.020313 -0.051170 0.002242 0.088222 -0.004267 -0.073523 -0.021874 -0.033585 -0.048553 -0.019119 -0.025310 0.053096 0.111063 0.035042 -0.082811 -0.073749 -0.010048 0.012265 -0.023893 -0.125340 0.026611 0.043258 -0.010473 -0.044428 -0.039251 -0.046891 -0.013008 0.062219 0.078732 -0.086303 0.016901 0.010331 -0.043754 -0.057733 -0.037964 0.024907 0.068143 -0.019992 -0.035030 0.038854 0.034345 -0.048839 -0.105419 0.043013 -0.023374 -0.077629 -0.076465 0.078564 -0.024519 0.041293 -0.032088 -0.007053 0.022618 -0.004657 -0.093970 -0.000199 0.004813 -0.044789 -0.127900 -0.033516 -0.043816 0.033056 -0.057619 0.004901 0.018863 0.039752 0.000739 -0.136350 -0.067819 -0.014856 0.058351 -0.014275 -0.000873 -0.039388 -0.017191 -0.051184 -0.046863 0.006143 -0.075998 -0.064695 0.046676 -0.020558 0.082474 0.160449 -0.027475 0.009541 -0.021876 0.027416 0.078049 0.089309 0.032928 -0.033272 0.048905 0.061164 0.054811 0.024527 -0.034978 -0.018083 -0.077601 0.034112 -0.021121 0.098856 0.019585 -0.058928 -0.016126 -0.011748 0.031588 0.003205 -0.077483 -0.002372 -0.113548 0.047445 -0.027094 -0.032843 0.042378 -0.074703 0.057001 0.012020 0.131156 0.002080 -0.065770 0.112443 0.047786 0.024492 -0.108401 0.016836 0.001478 0.041542 -0.067801 0.102876 -0.052808 -0.136035 0.073852 0.079966 -0.000586 0.034055 -0.053040 0.050461 -0.021550 0.014827 0.077605 -0.024783 -0.082388 0.074410 -0.033689 -0.010982 0.043733\n",
            "go_VERB 0.010490 0.094733 0.143699 0.040344 -0.103710 -0.000016 -0.014351 0.019653 0.069472 -0.046938 -0.057882 0.076405 -0.025230 0.026663 0.029986 -0.001605 -0.027803 0.037521 -0.050608 0.016215 0.025947 0.061172 -0.037448 -0.079232 0.071731 -0.085143 0.021494 -0.135554 -0.026115 -0.066408 0.022858 0.083231 0.020998 -0.049906 -0.079992 -0.060827 -0.028916 -0.029005 0.026067 -0.074869 0.073802 0.023593 -0.024348 -0.093236 0.006169 0.013119 0.007817 -0.088096 -0.012373 0.099807 0.011438 0.028583 0.025614 0.175403 0.007033 0.038856 0.004040 -0.088907 0.079697 0.037448 -0.128230 -0.066502 -0.018969 0.025777 0.035905 0.003710 -0.089079 0.071521 0.039237 0.052136 0.020986 -0.030793 -0.069486 -0.137115 0.008305 0.020813 -0.155342 0.000619 -0.033499 -0.104162 -0.061528 -0.043877 -0.042524 -0.032872 0.045071 0.072908 0.096057 0.141987 -0.078056 -0.013102 -0.026589 -0.073783 0.114807 0.077389 -0.041879 -0.052886 0.053710 0.036806 -0.035973 0.049071 -0.107199 -0.043581 0.016515 -0.029278 -0.026228 0.068037 -0.024183 0.040984 -0.020469 -0.103833 -0.007225 -0.073788 -0.051063 -0.037850 0.052581 -0.053090 -0.012198 -0.057343 0.024050 -0.046498 0.003065 -0.058912 0.043695 0.006340 0.060953 -0.008608 -0.029686 0.081187 -0.020058 0.059240 -0.061306 -0.002190 -0.020671 0.076712 0.049087 0.001153 0.087481 0.008559 0.069936 -0.015886 0.006122 0.038000 -0.071984 0.005263 0.060463 -0.051217 -0.034060 0.045217 0.059163 -0.048462 -0.005371 0.009663 0.081303 0.051019 -0.001248 -0.022637 0.016228 -0.006395 -0.053985 -0.014513 -0.017219 -0.010658 -0.012446 -0.035279 -0.003882 0.036453 0.029681 0.021278 0.006188 0.027861 0.076864 -0.042835 -0.022834 0.013928 0.066150 0.040982 -0.110985 -0.018865 0.006675 0.019173 0.021484 -0.021977 -0.035462 0.000464 -0.024281 0.010881 -0.064037 -0.024893 -0.095968 0.020834 -0.114225 -0.023433 -0.043971 0.014273 0.013481 -0.007542 0.079197 0.021280 -0.129871 0.080770 0.028912 -0.044134 -0.019904 -0.039406 -0.076024 0.058488 -0.094331 -0.082633 0.017676 -0.084006 -0.024444 -0.049778 -0.044615 -0.013499 -0.036736 -0.038579 -0.117319 0.012026 -0.007846 0.024003 -0.101645 0.111720 -0.010241 0.050279 -0.002212 0.060056 -0.116837 0.006078 -0.017954 -0.021794 0.020252 -0.031337 -0.032407 0.081086 -0.095125 0.041699 0.015953 -0.045653 -0.022522 -0.021422 -0.029167 0.052594 0.016523 0.081598 -0.027877 0.000609 0.012837 0.011880 0.074220 0.009736 0.006465 -0.140252 0.010762 -0.038319 0.038924 0.042537 0.005027 0.014024 0.024548 0.050131 -0.048069 -0.012616 -0.052162 -0.100378 0.067741 -0.067824 -0.020692 -0.043022 -0.038036 -0.016860 0.027835 0.140990 -0.045201 -0.069347 0.174518 -0.000236 0.008150 -0.039823 0.041197 0.056322 0.085883 0.027376 0.036537 0.094723 -0.103076 0.105746 0.059074 0.010947 0.099756 -0.027213 0.128793 -0.054593 0.025890 0.053512 0.005200 -0.035256 0.063273 -0.027069 0.046354 -0.002262\n"
          ]
        }
      ],
      "source": [
        "! wget -c http://vectors.nlpl.eu/repository/20/0.zip\n",
        "! unzip 0.zip\n",
        "! head -3 model.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E6OAvhw8-A7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530358b1-a79e-4af4-8856-40234ab28bab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.079924,  0.022442,  0.076919, -0.002863, -0.127531,  0.051287,\n",
              "       -0.095675, -0.0186  ,  0.051935, -0.052795, -0.06387 ,  0.043203,\n",
              "        0.004191, -0.012313,  0.105467,  0.013266,  0.077944, -0.047378,\n",
              "       -0.070682,  0.030184, -0.138833, -0.084701, -0.008782, -0.007199,\n",
              "        0.037337, -0.053   ,  0.01012 , -0.08398 , -0.005395,  0.047067,\n",
              "       -0.081584, -0.055433, -0.076233,  0.034964,  0.001818, -0.021349,\n",
              "       -0.030471,  0.059395, -0.009416, -0.045231,  0.023697,  0.023232,\n",
              "       -0.066061, -0.052923,  0.014266, -0.017893,  0.071192, -0.048203,\n",
              "        0.049017, -0.015226, -0.00352 ,  0.03574 , -0.030285,  0.060437,\n",
              "       -0.043873,  0.137786, -0.047175, -0.011424,  0.022692, -0.005124,\n",
              "       -0.061212,  0.101943,  0.023463,  0.041025,  0.06888 , -0.013031,\n",
              "       -0.065225,  0.095227,  0.019052,  0.046936, -0.042879, -0.002209,\n",
              "       -0.052348, -0.043899,  0.004041, -0.002902, -0.034435, -0.052031,\n",
              "       -0.006447, -0.024401, -0.030252, -0.032878, -0.068159,  0.033416,\n",
              "       -0.04269 ,  0.019662,  0.04012 ,  0.058976,  0.029993, -0.029652,\n",
              "        0.010839, -0.032159,  0.07516 ,  0.041139,  0.067883,  0.03689 ,\n",
              "        0.020009, -0.016392,  0.025741, -0.018238, -0.016563, -0.043439,\n",
              "        0.063738, -0.078791,  0.011032,  0.114438,  0.042613,  0.081926,\n",
              "        0.042998, -0.043929,  0.080331,  0.071411,  0.018528, -0.008023,\n",
              "       -0.01087 , -0.113086, -0.018197, -0.040677,  0.119319,  0.02217 ,\n",
              "        0.024936,  0.030918, -0.002363,  0.060279, -0.048892, -0.039093,\n",
              "        0.064734, -0.004759, -0.011862, -0.064946,  0.014299, -0.100136,\n",
              "        0.032387,  0.046257, -0.032856,  0.021791,  0.04659 ,  0.067181,\n",
              "       -0.011572, -0.02477 ,  0.208515, -0.013778,  0.07749 ,  0.036269,\n",
              "       -0.025311,  0.008743,  0.023088, -0.053799, -0.053703,  0.015289,\n",
              "        0.015006,  0.041584, -0.094973, -0.117299, -0.084588, -0.018441,\n",
              "        0.042019,  0.021581,  0.042777, -0.069088,  0.00425 , -0.040643,\n",
              "        0.003935, -0.086202, -0.01956 ,  0.080941, -0.017594, -0.069672,\n",
              "        0.024082,  0.014119,  0.070761, -0.088746, -0.087638, -0.046135,\n",
              "        0.087701,  0.000511, -0.003136,  0.011977,  0.001197, -0.011425,\n",
              "        0.061621,  0.112823, -0.032129,  0.074036, -0.027944, -0.011532,\n",
              "       -0.067085, -0.063712, -0.079273, -0.023087, -0.018246, -0.020162,\n",
              "        0.034302,  0.051851, -0.101516, -0.115903, -0.025035, -0.038374,\n",
              "       -0.156888,  0.161839,  0.167586, -0.050433, -0.001742,  0.000618,\n",
              "       -0.022424, -0.023192,  0.10138 , -0.026153,  0.031536, -0.019917,\n",
              "        0.031985,  0.045185, -0.115603, -0.018887,  0.033738,  0.001214,\n",
              "       -0.016206, -0.024897,  0.040704,  0.019266, -0.033014,  0.001941,\n",
              "       -0.048393,  0.074257, -0.018683, -0.000764,  0.04256 ,  0.003521,\n",
              "       -0.001621,  0.036552, -0.013271,  0.020076, -0.146136, -0.054995,\n",
              "       -0.101388, -0.004249,  0.074743, -0.088065,  0.097196, -0.015668,\n",
              "        0.040254, -0.015016,  0.094478,  0.105757, -0.02778 ,  0.039998,\n",
              "        0.038051,  0.004592,  0.113712, -0.13887 ,  0.01759 , -0.131265,\n",
              "       -0.032727, -0.048045,  0.094933,  0.062288, -0.000595,  0.082751,\n",
              "       -0.018606, -0.020001,  0.026897, -0.086625, -0.061415, -0.022437,\n",
              "        0.021244, -0.044401,  0.119859, -0.031017, -0.018063, -0.015677,\n",
              "       -0.07102 , -0.048613, -0.006237, -0.011565,  0.035263,  0.007643,\n",
              "       -0.028243, -0.005303, -0.033665,  0.069942,  0.038525, -0.047229,\n",
              "        0.047951,  0.019768, -0.040072, -0.017095,  0.009398, -0.107733,\n",
              "        0.073916,  0.010843,  0.052548, -0.059099,  0.001112,  0.07665 ,\n",
              "        0.054262, -0.043309,  0.011787, -0.097098,  0.00352 ,  0.045629],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "w_british = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True)\n",
        "w_british[15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-21wScRRf1E"
      },
      "source": [
        "Загрузим модель, обученную на британском национальном корпусе"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GpisLDDRf1T"
      },
      "source": [
        "Заметим, что размерность векторов в этом случае также равна 300. При этом через нижнее подчеркивание нужно указывать часть речи используемого слова. Слова следует приводить к нижнему регистру."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7VEcvPIRf1W",
        "outputId": "20f2a832-a6f2-480e-f2e3-55c9fa5401c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n",
            "lower is ok\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    print(w_british[\"London_NOUN\"].shape)\n",
        "    print('upper is ok')\n",
        "except:\n",
        "    print(w_british[\"london_NOUN\"].shape)\n",
        "    print('lower is ok')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# считаем косинусное расстояние между словами\n",
        "london_england_distance = w_british.distance(\"media_NOUN\", \"bread_NOUN\")\n",
        "moscow_england_distance = w_british.distance(\"media_NOUN\", \"bread_NOUN\")\n",
        "\n",
        "# выводим результаты\n",
        "print(f\"Косинусное расстояние между словами London и England: {london_england_distance}\")\n",
        "print(f\"Косинусное расстояние между словами Moscow и England: {moscow_england_distance}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIU7GtYIqIYW",
        "outputId": "e334b384-a62c-412b-82b6-4a7b1b70abe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Косинусное расстояние между словами London и England: 0.8856778591871262\n",
            "Косинусное расстояние между словами Moscow и England: 0.8856778591871262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w_british.most_similar(positive=[\"media_NOUN\"], negative=[\"media_NOUN\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbN9OWWb23j-",
        "outputId": "ee448cf2-fbd8-460e-a3c2-94ad766f562d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('0304_NUM', 0.0),\n",
              " ('Ardnave_PROPN', 0.0),\n",
              " ('Nicolas::Poussin_PROPN', 0.0),\n",
              " ('Jojo_PROPN', 0.0),\n",
              " ('Wytham_PROPN', 0.0),\n",
              " ('230mm_NOUN', 0.0),\n",
              " ('r10000_X', 0.0),\n",
              " ('non-combatant_ADJ', 0.0),\n",
              " ('sleekness_NOUN', 0.0),\n",
              " ('expectorate_VERB', 0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "\n",
        "word_list = [\"media_NOUN\", \"bread_NOUN\", \"cucumber_NOUN\", \"doctor_NOUN\"]\n",
        "\n",
        "# находим лишнее слово\n",
        "odd_word = w_british.doesnt_match(word_list)\n",
        "\n",
        "print(\"Лишнее слово:\", odd_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWmTcWmsqUuQ",
        "outputId": "d51ee6c6-a758-4f54-8a54-b303329966bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лишнее слово: media_NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfpohw153YQs"
      },
      "source": [
        "## Набор данных для оценки качества\n",
        "Скачаем датасет wordsim353. \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6c2--gQ3bJF",
        "outputId": "554ad1b4-711a-483a-ddae-29afcc5bfc7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-16 13:03:59--  http://alfonseca.org/pubs/ws353simrel.tar.gz\n",
            "Resolving alfonseca.org (alfonseca.org)... 162.215.249.67\n",
            "Connecting to alfonseca.org (alfonseca.org)|162.215.249.67|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5460 (5.3K) [application/x-gzip]\n",
            "Saving to: ‘ws353simrel.tar.gz’\n",
            "\n",
            "\rws353simrel.tar.gz    0%[                    ]       0  --.-KB/s               \rws353simrel.tar.gz  100%[===================>]   5.33K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-16 13:03:59 (302 MB/s) - ‘ws353simrel.tar.gz’ saved [5460/5460]\n",
            "\n",
            "wordsim353_sim_rel/wordsim353_agreed.txt\n",
            "wordsim353_sim_rel/wordsim353_annotator1.txt\n",
            "wordsim353_sim_rel/wordsim353_annotator2.txt\n",
            "wordsim353_sim_rel/wordsim_relatedness_goldstandard.txt\n",
            "wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\n",
            "tiger\tcat\t7.35\n",
            "tiger\ttiger\t10.00\n",
            "plane\tcar\t5.77\n",
            "train\tcar\t6.31\n",
            "television\tradio\t6.77\n"
          ]
        }
      ],
      "source": [
        "! wget -c http://alfonseca.org/pubs/ws353simrel.tar.gz \n",
        "! tar -xvf ws353simrel.tar.gz\n",
        "! head -5 wordsim353_sim_rel/wordsim_similarity_goldstandard.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgCXUELHRf2E"
      },
      "source": [
        "## Подготовка эталонной выборки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqy84Dmp3bYa"
      },
      "source": [
        "\n",
        "Из файла `wordsim_similarity_goldstandard.txt` извлечем пары слов и посчитаем косинусное сходство их векторов в обеих моделях. Посчитаем корреляцию оценок сходства в модели google-news-vectors с оценками аннотаторов в датасете, а затем - корреляцию сходства в модели на основе британского национального корпуса с оценками аннотаторов в датасете. Какая модель ближе к суждениям экспертов-разметчиков?\n",
        "\n",
        "(используем только те слова из wordsim, для которых находятся векторы на британском корпусе, помеченные как существительные!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Bpeg6FQd3clf",
        "outputId": "b4f2fb20-ed74-4d73-dd44-11c52c0ea49d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             first   second  score\n",
              "14            king    queen   8.58\n",
              "15            king     rook   5.92\n",
              "16          bishop    rabbi   6.69\n",
              "17            fuck      sex   9.44\n",
              "18        football   soccer   9.03\n",
              "..             ...      ...    ...\n",
              "109       consumer   energy   4.75\n",
              "110       ministry  culture   4.69\n",
              "111          smart  student   4.62\n",
              "112  investigation   effort   4.59\n",
              "113          image  surface   4.56\n",
              "\n",
              "[100 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0499a387-b8b0-4b9a-a320-237de1f092b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first</th>\n",
              "      <th>second</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>king</td>\n",
              "      <td>queen</td>\n",
              "      <td>8.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>king</td>\n",
              "      <td>rook</td>\n",
              "      <td>5.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>bishop</td>\n",
              "      <td>rabbi</td>\n",
              "      <td>6.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>fuck</td>\n",
              "      <td>sex</td>\n",
              "      <td>9.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>football</td>\n",
              "      <td>soccer</td>\n",
              "      <td>9.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>consumer</td>\n",
              "      <td>energy</td>\n",
              "      <td>4.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>ministry</td>\n",
              "      <td>culture</td>\n",
              "      <td>4.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>smart</td>\n",
              "      <td>student</td>\n",
              "      <td>4.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>investigation</td>\n",
              "      <td>effort</td>\n",
              "      <td>4.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>image</td>\n",
              "      <td>surface</td>\n",
              "      <td>4.56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0499a387-b8b0-4b9a-a320-237de1f092b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0499a387-b8b0-4b9a-a320-237de1f092b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0499a387-b8b0-4b9a-a320-237de1f092b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\", \n",
        "                 sep=\"\\t\", header=None)\n",
        "df.columns = [\"first\", \"second\", \"score\"]\n",
        "df.head(3)\n",
        "df = df[14:114]\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDcXFGZnRf2e"
      },
      "source": [
        "## Вычисление оценок similarity моделей\n",
        "Используем только те слова из wordsim, для которых находятся векторы на британском корпусе, помеченные как существительные, сформируйте 3 массива с оценкам схожести: \n",
        "\n",
        "1. Оценки (косинус между векторами), полученные в результате модели google-news-vectors\n",
        "\n",
        "2. Оценки (косинус между векторами) полученные в результате модели на основе британского национального корпуса\n",
        "\n",
        "3. Эталонные оценки из word_sim, для слов из которых находятся векторы на британском корпусе\n",
        "\n",
        "Пропущенные слова из word_sim представлены в блоке вывода."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gn_dist, br_dist, scores = [], [], []\n",
        "\n",
        "for row in df.iterrows():\n",
        "    \n",
        "  w1, w2 = row[1][\"first\"], row[1][\"second\"]\n",
        "\n",
        "  try:\n",
        "    # Получение векторов слов\n",
        "    gn_vec1, br_vec1 = w[w1], w_british[f\"{w1.lower()}_NOUN\"]\n",
        "    gn_vec2, br_vec2 = w[w2], w_british[f\"{w2.lower()}_NOUN\"]\n",
        "    \n",
        "    # Проверка, что слова являются существительными\n",
        "    if f'{w1.lower()}_NOUN' and f'{w2.lower()}_NOUN':\n",
        "        # Рассчет косинусного расстояния\n",
        "        gn_sim = w.similarity(w1, w2)\n",
        "        br_sim = w_british.similarity(f\"{w1.lower()}_NOUN\", f\"{w2.lower()}_NOUN\")\n",
        "        \n",
        "        # Добавление оценок в соответствующие массивы\n",
        "        gn_dist.append(gn_sim)\n",
        "        br_dist.append(br_sim)\n",
        "        scores.append(row[1][\"score\"])\n",
        "\n",
        "  except KeyError as e:\n",
        "    print(e, \"Skipping this word.\")\n",
        "print(scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHOITogZXOZV",
        "outputId": "5fc7c36a-eadf-4915-de2f-2f7ca42b5aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Key 'arafat_NOUN' not present\" Skipping this word.\n",
            "\"Key 'harvard_NOUN' not present\" Skipping this word.\n",
            "\"Key 'mexico_NOUN' not present\" Skipping this word.\n",
            "[8.58, 5.92, 6.69, 9.44, 9.03, 6.81, 6.63, 7.35, 8.46, 8.13, 6.87, 8.94, 8.96, 9.29, 8.83, 9.1, 8.87, 9.02, 9.29, 8.79, 7.52, 7.1, 7.38, 4.42, 8.42, 9.04, 8.0, 8.0, 7.08, 6.85, 7.0, 4.77, 5.62, 8.08, 6.71, 5.58, 8.45, 8.08, 8.02, 5.85, 6.04, 6.85, 2.92, 3.69, 2.15, 7.42, 7.27, 8.66, 6.22, 6.5, 7.59, 7.56, 5.0, 4.63, 7.88, 5.0, 8.97, 6.44, 8.88, 6.88, 7.81, 7.63, 8.44, 7.63, 7.78, 9.22, 7.13, 7.89, 7.47, 8.34, 8.7, 7.81, 5.7, 8.36, 8.3, 5.25, 8.53, 6.88, 5.56, 7.83, 7.59, 7.19, 6.31, 5.0, 5.0, 4.97, 4.94, 4.94, 4.88, 4.81, 4.75, 4.75, 4.75, 4.69, 4.62, 4.59, 4.56]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPyeIR2QtSec"
      },
      "source": [
        "## Выбор модели: корреляция с экспертами\n",
        "\n",
        "Вычислите корреляцию Спирмена для каждой модели по сравнению с эталонными оценками из word_sim.\n",
        "\n",
        "Результаты представлены в блоке вывода."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtlAncsQANfx"
      },
      "source": [
        "Можно заметить, что модель google-news-vectors несколько выигрывает в данном случае."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "gn_corr, br_corr = spearmanr(scores, gn_dist)[0], spearmanr(scores, br_dist)[0]\n",
        "\n",
        "print(\"Корреляция Спирмена для модели Google News Vectors:\", round(gn_corr,3))\n",
        "print(\"Корреляция Спирмена для модели на основе британского национального корпуса:\", round(br_corr, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNPDIIcHX7Oe",
        "outputId": "7d604b90-bc1f-430b-fa25-35cf37255d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Корреляция Спирмена для модели Google News Vectors: 0.694\n",
            "Корреляция Спирмена для модели на основе британского национального корпуса: 0.646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gn_dist, br_dist, scores = [], [], []\n",
        "gn_dist_2, br_dist_2 = [], []\n",
        "\n",
        "for row in df.iterrows():\n",
        "    \n",
        "  w1, w2 = row[1][\"first\"], row[1][\"second\"]\n",
        "  try:\n",
        "    gn = w.similarity(w1, w2)\n",
        "    br = w_british.similarity(w1.lower() + \"_NOUN\", w2.lower() + \"_NOUN\")\n",
        "    gn_dist.append(gn)\n",
        "    br_dist.append(br)\n",
        "    br_dist_2.append(1 - w_british.distance(w1.lower() + \"_NOUN\", w2.lower() + \"_NOUN\"))\n",
        "    gn_dist_2.append(1 - w.distance(w1, w2))\n",
        "    scores.append(row[1][\"score\"])\n",
        "  except KeyError as e:\n",
        "    print(e, \"Skipping this word.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hXqD5q2fmSo",
        "outputId": "4566fed8-2b5e-462c-8fe2-e666a4515d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Key 'arafat_NOUN' not present\" Skipping this word.\n",
            "\"Key 'harvard_NOUN' not present\" Skipping this word.\n",
            "\"Key 'mexico_NOUN' not present\" Skipping this word.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}